{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context\n",
    "\n",
    "## Quick reminder on last course\n",
    "\n",
    "XX\n",
    "\n",
    "## Goal of this course\n",
    "\n",
    "XX\n",
    "\n",
    "\n",
    "# Concepts\n",
    "\n",
    "## Estimate the parameters\n",
    "\n",
    "As we are in the supervised framework, each model will try here to relate the target output y - what we want to forecast, to the features X - what we can observe, using more or less complex formulas. These formulas will contains parameters that we need to estimate.\n",
    "\n",
    "For all algorithms we will actually minimize __the loss function__ - which quantifies how far our predictions on X will be with our model and its set of parameters to the correct output y. The estimation process can be tricky as we are considering complex relations between our features and output. Fortunately, Python is doing all the maths for us! If you want to learn more on this: __XX (SGD etc.)__\n",
    "\n",
    "\n",
    "## Training and test sets\n",
    " \n",
    "When training machine learning models - i.e. estimating the parameters, we want to avoid training the model on all of the possible data that we have available. This is to avoid creating a model that is to specifically atuned to our training data and will later not generalise - this is often called __overfitting__. \n",
    "\n",
    "So instead we will spilt our data into __training and test sets__. The state of the art is to do __cross-validation__. Basically we will split the dataset in _n_ (usually 5) chunks and:\n",
    "- train our model on the features dataset consolidated with _(n-1)_ chunks (the training set);\n",
    "- compute the error, i.e. evaluate its predictions against the target y - that we _do_ observe, on the remaining chunk (the test set);\n",
    "- and reiterate this process for all the possible combinations of _(n-1)_ vs 1 chunks of data (_n_ combinations).\n",
    "\n",
    "At the end we then have computed _n_ errors (see the model evaluation part for more details on the metrics used). We will take the average of the errors for model selection purposes.\n",
    "\n",
    "For many complex problems and datasets the 'bleeding' of knowledge from the evaluation set into the training set can be a real problem. In that case our model will perform much worse in production than what we would have assumed. And so it is really important to make sure that we don't have information in the training set that we would not have been able to have at that time.\n",
    "\n",
    "Note also that there are lots of different way to split the dataset in training and test ones. Here we could also have kept the last two weeks for testing purpose and train our model on the remaining timeframe. It's better to assess if our model can generalise to another _date_, we are loosing one `twoweek` feature though as in this case we have to train on `twoweek` 1 to 7, and thus our target in the training becomes the metric built on `twoweek` 7, and the features on the past 12 weeks (`twoweek` 1 to 6).\n",
    "\n",
    "What kind of modelling?\n",
    "\n",
    "## Model Selection\n",
    " \n",
    "The first decision you need to make in the model selection process in the supervised framework is whether you plan to use a __classifier__ or a __regressor model__. Classifiers make discrete predictions about a datapoint into a finite number of classes while regressors make linear predictions.  \n",
    " \n",
    "Different models work in different ways and are more or less suitable for different problems. Fortunately, however,  understanding these specific differences is not essential to solve your data problems. The python module `scikit learn` contains all of the models that you are likely to need and the format of the data it requires is standardised across models. This makes it very easy to try your data using a myriad of different models and choose the one that performs best on your data.\n",
    " \n",
    "In our current project we use both classifiers and regressors to predict engagement. In the classifier we simply try to predict whether someone has watched any content in the two-week period while in the regressor we attempt to predict the number of minutes watched by the viewer within the two-week period.\n",
    "\n",
    "We won't tacke both prediction tasks here. This course focused on classification and the next one will focus on regression.\n",
    "\n",
    "## Model Evaluation\n",
    "\n",
    "To evaluate our models there are different metrics we can use. For classifiers we can use __the accuracy__ (percentage correct) or __the ROC curve__. The accuracy is the simplest metric but it gives us little insight into the behaviour of the model. ROC curves (and __the area under the curve__ statistic) give us a greater understanding of the separability of the data. For more details see https://en.wikipedia.org/wiki/Receiver_operating_characteristic.\n",
    "\n",
    "We will evaluate our model in different stages on the model selection process. First, when training our model we will compute a test or __out-of-sample error__ (actually _n_ ones using cross-validation). It's called out-of-sample here because the predictions are made on data the model has never seen before. \n",
    "\n",
    "Usually models have also __hyperparameters__ - parameters that we don't need to estimate but to tune during the training process. A good way of doing that is to do a grid search and to evaluate the model with the different combinations of hyperparameters. We will then retain the one with the lowest error. \n",
    "\n",
    "Once we have selected the best set of hyperparameters for a given model, or the best kind of model for the data we have gor, we can retrain it on the entire dataset and compute its __in-sample__ error, i.e. evaluate its predictions with the observed targets, keeping in mind that we have used this data to build the model this time.   \n",
    "\n",
    "Finally, when computing the performance of a model based on a given metric it's important to bare in mind what the performance of a simple model would be. Usually we consider the completely random one as a baseline. Any model you build must be evaluated in terms of improvement over this performance. \n",
    "\n",
    "# Classification\n",
    "\n",
    "The first thing to do is to get our data back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We put both target arrays (regression and classification) in the same txt file\n",
    "# As both target arrays have the same size we just need to split it it two\n",
    "# and get the correct part for the prediction task\n",
    "target = np.split(np.loadtxt('target.txt'), 2)[1].flatten()\n",
    "features = pd.read_csv('features.csv')\n",
    "\n",
    "# User id as index\n",
    "features = features.set_index('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tw_lag7_watched</th>\n",
       "      <th>tw_lag6_watched</th>\n",
       "      <th>tw_lag5_watched</th>\n",
       "      <th>tw_lag4_watched</th>\n",
       "      <th>tw_lag3_watched</th>\n",
       "      <th>tw_lag2_watched</th>\n",
       "      <th>tw_lag1_watched</th>\n",
       "      <th>average_completion</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>total_watched</th>\n",
       "      <th>...</th>\n",
       "      <th>most_weekday_weekday_1</th>\n",
       "      <th>most_weekday_weekday_2</th>\n",
       "      <th>most_weekday_weekday_3</th>\n",
       "      <th>most_weekday_weekday_4</th>\n",
       "      <th>most_weekday_weekday_5</th>\n",
       "      <th>most_weekday_weekday_6</th>\n",
       "      <th>most_timeday_Afternoon</th>\n",
       "      <th>most_timeday_Evening</th>\n",
       "      <th>most_timeday_Morning</th>\n",
       "      <th>most_timeday_Night</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0001c6</th>\n",
       "      <td>16.679200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371496</td>\n",
       "      <td>2</td>\n",
       "      <td>16.831750</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000c1a</th>\n",
       "      <td>0.162867</td>\n",
       "      <td>0.147467</td>\n",
       "      <td>107.0984</td>\n",
       "      <td>145.686233</td>\n",
       "      <td>2.286283</td>\n",
       "      <td>100.487767</td>\n",
       "      <td>132.432083</td>\n",
       "      <td>0.233136</td>\n",
       "      <td>28</td>\n",
       "      <td>488.301100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001c53</th>\n",
       "      <td>1.866300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.309867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489419</td>\n",
       "      <td>3</td>\n",
       "      <td>3.176167</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001d44</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>14.547700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.248017</td>\n",
       "      <td>0.058203</td>\n",
       "      <td>2</td>\n",
       "      <td>14.795717</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002b2e</th>\n",
       "      <td>291.477033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.228233</td>\n",
       "      <td>17</td>\n",
       "      <td>291.477033</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tw_lag7_watched  tw_lag6_watched  tw_lag5_watched  tw_lag4_watched  \\\n",
       "user_id                                                                       \n",
       "0001c6         16.679200         0.000000           0.0000         0.000000   \n",
       "000c1a          0.162867         0.147467         107.0984       145.686233   \n",
       "001c53          1.866300         0.000000           0.0000         0.000000   \n",
       "001d44          0.000000         0.000000           0.0000        14.547700   \n",
       "002b2e        291.477033         0.000000           0.0000         0.000000   \n",
       "\n",
       "         tw_lag3_watched  tw_lag2_watched  tw_lag1_watched  \\\n",
       "user_id                                                      \n",
       "0001c6          0.000000         0.152550         0.000000   \n",
       "000c1a          2.286283       100.487767       132.432083   \n",
       "001c53          1.309867         0.000000         0.000000   \n",
       "001d44          0.000000         0.000000         0.248017   \n",
       "002b2e          0.000000         0.000000         0.000000   \n",
       "\n",
       "         average_completion  total_sessions  total_watched  \\\n",
       "user_id                                                      \n",
       "0001c6             0.371496               2      16.831750   \n",
       "000c1a             0.233136              28     488.301100   \n",
       "001c53             0.489419               3       3.176167   \n",
       "001d44             0.058203               2      14.795717   \n",
       "002b2e             0.228233              17     291.477033   \n",
       "\n",
       "                ...          most_weekday_weekday_1  most_weekday_weekday_2  \\\n",
       "user_id         ...                                                           \n",
       "0001c6          ...                               1                       0   \n",
       "000c1a          ...                               0                       0   \n",
       "001c53          ...                               0                       1   \n",
       "001d44          ...                               0                       0   \n",
       "002b2e          ...                               0                       1   \n",
       "\n",
       "         most_weekday_weekday_3  most_weekday_weekday_4  \\\n",
       "user_id                                                   \n",
       "0001c6                        0                       0   \n",
       "000c1a                        1                       0   \n",
       "001c53                        0                       0   \n",
       "001d44                        0                       0   \n",
       "002b2e                        0                       0   \n",
       "\n",
       "         most_weekday_weekday_5  most_weekday_weekday_6  \\\n",
       "user_id                                                   \n",
       "0001c6                        0                       0   \n",
       "000c1a                        0                       0   \n",
       "001c53                        0                       0   \n",
       "001d44                        0                       1   \n",
       "002b2e                        0                       0   \n",
       "\n",
       "         most_timeday_Afternoon  most_timeday_Evening  most_timeday_Morning  \\\n",
       "user_id                                                                       \n",
       "0001c6                        0                     1                     0   \n",
       "000c1a                        0                     0                     1   \n",
       "001c53                        0                     0                     1   \n",
       "001d44                        0                     0                     1   \n",
       "002b2e                        0                     1                     0   \n",
       "\n",
       "         most_timeday_Night  \n",
       "user_id                      \n",
       "0001c6                    0  \n",
       "000c1a                    0  \n",
       "001c53                    0  \n",
       "001d44                    0  \n",
       "002b2e                    0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline score\n",
    "\n",
    "Usually dealing with 0/1 classification problem we talk about __scoring__. And the probability to belong to the class 1 (usually our class of interest) is the score.\n",
    "\n",
    "As mentionned before we should have a baseline to compare the performance of our models with. We usually choose as a baseline score the one obtained by a random allocation of our users. Allocating randomly 100 users to the class 1, the accuracy will depend on the effective concentration of class 1 in the entire population. If we observe 30% of class 1 in the population, then we should have 30 correct predictions out of our 100 users labeled class 1 with this random allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40551224332930713"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check our baseline score\n",
    "sum(target)/len(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for any classification model to add value we would like it to perform with an accuracy of more than 40% (otherwise guessing based on the proportions would be a better model).\n",
    "\n",
    "We will try 4 different kind of modelling here.\n",
    "\n",
    "## Tree based classification model\n",
    "\n",
    "Decision trees are quite simple classifier. __BLA BLA BLA__ <br> https://en.wikipedia.org/wiki/Decision_tree_learning\n",
    "\n",
    "For all the models we use the Python `scikit learn` library, really easy to use and well documented. For decision trees see: http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's build a simple tree based classification model\n",
    "from sklearn import tree\n",
    "\n",
    "# Accuracy as our error evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# We will use cross validation, so import helper functions for this\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and hyperparameters tuning\n",
    "As explained before we will do cross-validation during the training process. There is no need to manually split our dataset as `scikit learn` provides a function to do so. \n",
    "\n",
    "There are two hyperparameters in decision trees that we need to tune:\n",
    "- the maximum depth of the tree `max_depth` (default _None_);\n",
    "- the minimum number of samples required to be at a leaf node `min_samples_leaf` (default 1).\n",
    "\n",
    "Here we will keep track of the hyperparameters that maximize the accuracy (our error score). These settings will define our _best decision tree_ model. \n",
    "\n",
    "The score returns by our code is the average of the out-of-sample scores computed during the cross-validation process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the model and develop a simple grid search against some key parameters\n",
    "param_max_depth=[2,3,4,6,8,10]\n",
    "param_min_leaf=[75,90,100,110,125,150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Settings: Max Depth: 4 - Min Sample Leaf: 100\n",
      "Score: 0.794992688868\n"
     ]
    }
   ],
   "source": [
    "# Let's keep track of our best parameters\n",
    "best_score=0\n",
    "best_param=[0,0]\n",
    "\n",
    "# We will use the itertools library to try all the possible combinations of paramaters\n",
    "# We could also have used the gridsearchCV capability in scikit learn\n",
    "for c in itertools.product(param_max_depth,param_min_leaf):\n",
    "    treeclass=tree.DecisionTreeClassifier(max_depth=c[0],min_samples_leaf=c[1])\n",
    "    scores=cross_val_score(treeclass,\n",
    "                           features,\n",
    "                           target,\n",
    "                           scoring='accuracy')\n",
    "    if np.mean(scores)>best_score:\n",
    "        best_score=np.mean(scores)\n",
    "        best_param=c\n",
    "\n",
    "# Print the overall best results\n",
    "print('Best Settings: Max Depth:',best_param[0], '- Min Sample Leaf:',best_param[1])\n",
    "print('Score:', best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best decision tree model\n",
    "\n",
    "Now that we have identified our hyperparameters (note that we could do a thinier grid search) we can train our model on the entire dataset. The more data we have got, the more we are going to be able to get accurate trends - baring in mind the overfitting issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's keep our best model (hyperparameters tuned)\n",
    "treeclass=tree.DecisionTreeClassifier(max_depth=best_param[0],\n",
    "                                      min_samples_leaf=best_param[1])\n",
    "mod1=treeclass.fit(features,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the in-sample accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79795761502141205"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The model has been trained on the entire dataset - i.e. the output we are comparing our\n",
    "# predictions with here have been used to estimate the parameters\n",
    "mod1.score(features,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also have a look at the features that matter in building the tree / in the decision process. `Scikit learn` gives us the features or __Gini importance__. __DETAILS__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tw_lag1_watched</td>\n",
       "      <td>0.720014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>number_watched</td>\n",
       "      <td>0.115590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tw_lag3_watched</td>\n",
       "      <td>0.090706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tw_lag2_watched</td>\n",
       "      <td>0.054184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tw_lag5_watched</td>\n",
       "      <td>0.012255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>num_genre</td>\n",
       "      <td>0.006670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>average_completion</td>\n",
       "      <td>0.000581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>most_weekday_weekday_4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>most_genre_Weather</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>most_weekday_weekday_0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feature  importance\n",
       "0         tw_lag1_watched    0.720014\n",
       "1          number_watched    0.115590\n",
       "2         tw_lag3_watched    0.090706\n",
       "3         tw_lag2_watched    0.054184\n",
       "4         tw_lag5_watched    0.012255\n",
       "5               num_genre    0.006670\n",
       "6      average_completion    0.000581\n",
       "7  most_weekday_weekday_4    0.000000\n",
       "8      most_genre_Weather    0.000000\n",
       "9  most_weekday_weekday_0    0.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features importance\n",
    "feature_imp1=pd.DataFrame(\n",
    "    {'feature': list(features.columns),\n",
    "     'importance': list(mod1.feature_importances_)\n",
    "    })\n",
    "feature_imp1.sort_values(by='importance', ascending=False).reset_index(drop=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We therefore see that the total minutes watched the two weeks before matters the most. The number of content watched within the past 14 weeks as well but to a lesser extent. Which is quite expected and is a good _business_ check of the relevance of the model. \n",
    "\n",
    "## Random Forest\n",
    "A random forest is a collection of decision trees. The decesion tree in the part above was built using the whole dataset considering all features. Here the model selects randomly a subset of the data and a particular number of features to train on a decision tree. Similarly a number of decision trees are grown, each will probably have a different subset since it is being randomly selected and hence each decision tree will be different, and each tree will vote for a particular class and the class which gets maximum number of votes is the predicted class.\n",
    "\n",
    "The idea behind random forest is to prevent overfitting building smaller trees and combining them.\n",
    "\n",
    "For more details on it: https://en.wikipedia.org/wiki/Random_forest <br>\n",
    "And the `scikit learn` documentation: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's build a random forrest\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and hyperparameters tuning\n",
    "We need to tune the same hyperparameters than for a decision tree model:\n",
    "- the maximum depth of the tree `max_depth` (default _None_);\n",
    "- the minimum number of samples required to be at a leaf node `min_samples_leaf` (default 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the model and develop a simple grid search against some key parameters\n",
    "param_max_depth=[2,3,4,6,8,10]\n",
    "param_min_leaf=[75,90,100,110,125,150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Settings: Max Depth: 8 - Min Sample Leaf: 90\n",
      "Score: 0.794882859105\n"
     ]
    }
   ],
   "source": [
    "# Let's keep track of our best parameters\n",
    "best_score=0\n",
    "best_param=[0,0]\n",
    "\n",
    "# We will use the itertools library to try all the possible combinations of paramaters\n",
    "# We could also have used the gridsearchCV capability in scikit learn\n",
    "for c in itertools.product(param_max_depth,param_min_leaf):\n",
    "    forrestclass=RandomForestClassifier(n_estimators=200,\n",
    "                                        max_depth=c[0],min_samples_leaf=c[1])\n",
    "    scores=cross_val_score(forrestclass,\n",
    "                           features,\n",
    "                           target,\n",
    "                           scoring='accuracy')\n",
    "    if np.mean(scores)>best_score:\n",
    "        best_score=np.mean(scores)\n",
    "        best_param=c\n",
    "\n",
    "# Print the overall best results\n",
    "print('Best Settings: Max Depth:',best_param[0], '- Min Sample Leaf:',best_param[1])\n",
    "print('Score:', best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is the same as for a decision tree modeling. \n",
    "\n",
    "### Best RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's keep our best model (hyperparameters tuned)\n",
    "forrestclass=RandomForestClassifier(n_estimators=200,\n",
    "                                    max_depth=best_param[0],\n",
    "                                    min_samples_leaf=best_param[1])\n",
    "mod2=forrestclass.fit(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7992752827495333"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In-sample accuracy\n",
    "mod2.score(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tw_lag1_watched</td>\n",
       "      <td>0.222952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tw_lag2_watched</td>\n",
       "      <td>0.144430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>total_sessions</td>\n",
       "      <td>0.112129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tw_lag3_watched</td>\n",
       "      <td>0.106837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>number_watched</td>\n",
       "      <td>0.098646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>num_weekday</td>\n",
       "      <td>0.092117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_genre</td>\n",
       "      <td>0.061785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>total_watched</td>\n",
       "      <td>0.047196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tw_lag5_watched</td>\n",
       "      <td>0.033521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tw_lag4_watched</td>\n",
       "      <td>0.027075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature  importance\n",
       "0  tw_lag1_watched    0.222952\n",
       "1  tw_lag2_watched    0.144430\n",
       "2   total_sessions    0.112129\n",
       "3  tw_lag3_watched    0.106837\n",
       "4   number_watched    0.098646\n",
       "5      num_weekday    0.092117\n",
       "6        num_genre    0.061785\n",
       "7    total_watched    0.047196\n",
       "8  tw_lag5_watched    0.033521\n",
       "9  tw_lag4_watched    0.027075"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features importance\n",
    "feature_imp2=pd.DataFrame(\n",
    "    {'feature': list(features.columns),\n",
    "     'importance': list(mod2.feature_importances_)\n",
    "    })\n",
    "feature_imp2.sort_values(by='importance', ascending=False).reset_index(drop=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__XXX COMMENTS__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Let's try something that is not based on decision trees. \n",
    "\n",
    "__DETAIL BASIC COCNEPTS__\n",
    "\n",
    "__GIVE DOC__ Scikit documentation: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's build a logistic regression\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and hyperparameters tuning\n",
    "XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup the model and develop a simple grid search against some key parameters\n",
    "param_C=[0.001,0.01,0.1,1.0,10,100,1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Settings: C: 0.01\n",
      "Score: 0.773690489886\n"
     ]
    }
   ],
   "source": [
    "# Let's keep track of our best parameters\n",
    "best_score=0\n",
    "best_param=0\n",
    "\n",
    "# we will setup a manual grid search, but you can also use the gridsearchCV capability in sklearn\n",
    "for i in param_C:\n",
    "    logclass=linear_model.LogisticRegression(C=i)\n",
    "    scores=cross_val_score(logclass,\n",
    "                           features,\n",
    "                           target,\n",
    "                           scoring='accuracy')\n",
    "    if np.mean(scores)>best_score:\n",
    "        best_score=np.mean(scores)\n",
    "        best_param=i\n",
    "\n",
    "# print the overall best results\n",
    "print('Best Settings: C:',best_param)\n",
    "print('Score:', best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__COMMENTS__\n",
    "\n",
    "### Best logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's keep our best model (hyperparameters tuned)\n",
    "logclass=linear_model.LogisticRegression(C=best_param)\n",
    "mod3=logclass.fit(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77709454265949274"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In-sample accuracy\n",
    "mod3.score(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.254606</td>\n",
       "      <td>num_weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.113189</td>\n",
       "      <td>num_genre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007645</td>\n",
       "      <td>number_watched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005754</td>\n",
       "      <td>tw_lag1_watched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001347</td>\n",
       "      <td>tw_lag2_watched</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       coef          feature\n",
       "0  0.254606      num_weekday\n",
       "1  0.113189        num_genre\n",
       "2  0.007645   number_watched\n",
       "3  0.005754  tw_lag1_watched\n",
       "4  0.001347  tw_lag2_watched"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimated coefficients\n",
    "coef_mod3=pd.DataFrame(\n",
    "    {'feature': list(features.columns),\n",
    "     'coef': list(mod3.coef_.flatten())\n",
    "    })\n",
    "coef_mod3.sort_values(by='coef',ascending=False).reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.282503</td>\n",
       "      <td>most_genre_Factual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.283514</td>\n",
       "      <td>most_genre_Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.289396</td>\n",
       "      <td>most_timeday_Afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.305260</td>\n",
       "      <td>most_timeday_Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-0.394988</td>\n",
       "      <td>most_timeday_Evening</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coef                 feature\n",
       "31 -0.282503      most_genre_Factual\n",
       "32 -0.283514        most_genre_Drama\n",
       "33 -0.289396  most_timeday_Afternoon\n",
       "34 -0.305260      most_timeday_Night\n",
       "35 -0.394988    most_timeday_Evening"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_mod3.sort_values(by='coef',ascending=False).reset_index(drop=True).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ COMMENTS__ <br>\n",
    "__P VALUES ??\n",
    "AND which threshold ...__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)\n",
    "\n",
    "__DETAIL BASIC CONCEPTS__\n",
    "\n",
    "__GIVE DOC__ Scikit documentation: http://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's try to get some non linear patterns\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and hyperparameters tuning\n",
    "XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup the model and develop a simple grid search against some key parameters\n",
    "param_C=[0.001,0.01,0.1,1.0,10,100,1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Settings: C: 1.0\n",
      "Score: 0.692433069322\n"
     ]
    }
   ],
   "source": [
    "# Let's keep track of our best parameters\n",
    "best_score=0\n",
    "best_param=0\n",
    "\n",
    "# we will setup a manual grid search, but you can also use the gridsearchCV capability in sklearn\n",
    "for i in param_C:\n",
    "    svcclass=svm.SVC(C=i)\n",
    "    scores=cross_val_score(svcclass,\n",
    "                           features,\n",
    "                           target,\n",
    "                           scoring='accuracy')\n",
    "    if np.mean(scores)>best_score:\n",
    "        best_score=np.mean(scores)\n",
    "        best_param=i\n",
    "\n",
    "# print the overall best results\n",
    "print('Best Settings: C:',best_param)\n",
    "print('Score:', best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__COMMENTS__\n",
    "\n",
    "### Best SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's keep our best model (hyperparameters tuned)\n",
    "svcclass=svm.SVC(C=best_param)\n",
    "mod4=svcclass.fit(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94729329087515102"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In-sample error\n",
    "mod4.score(features,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__CONCLUSION BEST MODEL AND INSIGHTS BLABLABLA__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
