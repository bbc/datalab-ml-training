{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Four: Build a Regressor\n",
    "\n",
    "Expected time to complete: XX minutes\n",
    "\n",
    "## Goal of this Course\n",
    "During this course we will build a regressor to forecast the minutes watched within the last two-week group.\n",
    "\n",
    "This course is split into the following parts:\n",
    "- <a href='#context'>Context</a> \n",
    "- <a href='#model_evaluation'>Model Evaluation</a> \n",
    "- <a href='#baseline_forecast'>Baseline Forecast</a>\n",
    "    - <a href='#load_data'>Load the Data</a>\n",
    "    - <a href='#define_baseline'>Define a Baseline</a>\n",
    "\n",
    "\n",
    "- <a href='#linear_reg'>Linear Regression</a>\n",
    "    - <a href='#model_training'>Model Training</a>\n",
    "    - <a href='#out_sample_error'>Out-of-Sample Error</a>\n",
    "    - <a href='#in_sample_error'>In-Sample Error and Estimated Coefficients</a>\n",
    "\n",
    "\n",
    "- <a href='#ridge_reg'>Ridge Regression</a>\n",
    "    - <a href='#model_training2'>Model Training and Hyperparameters Tuning</a>\n",
    "    - <a href='#best_ridge_reg'>Best Ridge Regression</a>\n",
    "\n",
    "\n",
    "- <a href='#lasso_reg'>Lasso Regression</a>\n",
    "    - <a href='#model_training3'>Model Training and Hyperparameters Tuning</a>\n",
    "    - <a href='#best_lasso_reg'>Best Lasso Regression</a>\n",
    "\n",
    "\n",
    "- <a href='#combine'>Combine the Regression and Classification Models</a>\n",
    "\n",
    "<a id='context'></a>\n",
    "# Context\n",
    "In the previous tutorial we explained how the training process works and how to evaluate our models in the classification framework. We built few models to predict whether a user will consume content on the last two-week group based on his past behaviour on the 7 two-week groups before. \n",
    "\n",
    "Forecasting if a user will consume content is very usefull. It allows for example to focus our efforts on the ones who are not likely to come back.\n",
    "\n",
    "The users who are likely to come back within the last two-week period might also have different levels of engagement. Understanding to what extent they will consume content is key for the BBC to personnalise their experience with the product.   \n",
    "\n",
    "In order to forecast the minutes watched within the next two-week group we will first define our evaluation metric. As for the classifier, we will then ctry different models and compare their performances with a baseline. \n",
    "\n",
    "\n",
    "<a id='model_evaluation'></a>\n",
    "# Model Evaluation\n",
    "\n",
    "For regressors, the evaluation of the model is less straightforward and id usually based upon the average residual between the actual data and the model predictions. __Root mean squared error__ (RMSE) and __mean absolute error__ (MAE) are two commonly used examples of these. Once we have a representation of the error produced by the model we can compare that error with the error of the most simple model of the data (usually the mean). This statistic is known as the coefficient of determination or __R-squared__ and represents the part of variability the model managed to get.\n",
    "\n",
    "<a id='baseline_forecast'></a>\n",
    "# Baseline Forecast\n",
    "\n",
    "<a id='load_data'></a>\n",
    "## Load the Data\n",
    "The first thing to do is to get our data back and make sure we have the correct one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We put both target arrays (regression and classification) in the same txt file\n",
    "# As both target arrays have the same size we just need to split it it two\n",
    "# and get the correct part for the prediction task\n",
    "target = np.split(np.loadtxt('target.txt'), 2)[0].flatten()\n",
    "features = pd.read_csv('features.csv')\n",
    "\n",
    "# User id as index\n",
    "features = features.set_index('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tw_lag7_watched</th>\n",
       "      <th>tw_lag6_watched</th>\n",
       "      <th>tw_lag5_watched</th>\n",
       "      <th>tw_lag4_watched</th>\n",
       "      <th>tw_lag3_watched</th>\n",
       "      <th>tw_lag2_watched</th>\n",
       "      <th>tw_lag1_watched</th>\n",
       "      <th>average_completion</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>total_watched</th>\n",
       "      <th>...</th>\n",
       "      <th>most_weekday_weekday_1</th>\n",
       "      <th>most_weekday_weekday_2</th>\n",
       "      <th>most_weekday_weekday_3</th>\n",
       "      <th>most_weekday_weekday_4</th>\n",
       "      <th>most_weekday_weekday_5</th>\n",
       "      <th>most_weekday_weekday_6</th>\n",
       "      <th>most_timeday_Afternoon</th>\n",
       "      <th>most_timeday_Evening</th>\n",
       "      <th>most_timeday_Morning</th>\n",
       "      <th>most_timeday_Night</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0001c6</th>\n",
       "      <td>16.679200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371496</td>\n",
       "      <td>2</td>\n",
       "      <td>16.831750</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000c1a</th>\n",
       "      <td>0.162867</td>\n",
       "      <td>0.147467</td>\n",
       "      <td>107.0984</td>\n",
       "      <td>145.686233</td>\n",
       "      <td>2.286283</td>\n",
       "      <td>100.487767</td>\n",
       "      <td>132.432083</td>\n",
       "      <td>0.233136</td>\n",
       "      <td>28</td>\n",
       "      <td>488.301100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001c53</th>\n",
       "      <td>1.866300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.309867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489419</td>\n",
       "      <td>3</td>\n",
       "      <td>3.176167</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001d44</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>14.547700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.248017</td>\n",
       "      <td>0.058203</td>\n",
       "      <td>2</td>\n",
       "      <td>14.795717</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002b2e</th>\n",
       "      <td>291.477033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.228233</td>\n",
       "      <td>17</td>\n",
       "      <td>291.477033</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tw_lag7_watched  tw_lag6_watched  tw_lag5_watched  tw_lag4_watched  \\\n",
       "user_id                                                                       \n",
       "0001c6         16.679200         0.000000           0.0000         0.000000   \n",
       "000c1a          0.162867         0.147467         107.0984       145.686233   \n",
       "001c53          1.866300         0.000000           0.0000         0.000000   \n",
       "001d44          0.000000         0.000000           0.0000        14.547700   \n",
       "002b2e        291.477033         0.000000           0.0000         0.000000   \n",
       "\n",
       "         tw_lag3_watched  tw_lag2_watched  tw_lag1_watched  \\\n",
       "user_id                                                      \n",
       "0001c6          0.000000         0.152550         0.000000   \n",
       "000c1a          2.286283       100.487767       132.432083   \n",
       "001c53          1.309867         0.000000         0.000000   \n",
       "001d44          0.000000         0.000000         0.248017   \n",
       "002b2e          0.000000         0.000000         0.000000   \n",
       "\n",
       "         average_completion  total_sessions  total_watched  \\\n",
       "user_id                                                      \n",
       "0001c6             0.371496               2      16.831750   \n",
       "000c1a             0.233136              28     488.301100   \n",
       "001c53             0.489419               3       3.176167   \n",
       "001d44             0.058203               2      14.795717   \n",
       "002b2e             0.228233              17     291.477033   \n",
       "\n",
       "                ...          most_weekday_weekday_1  most_weekday_weekday_2  \\\n",
       "user_id         ...                                                           \n",
       "0001c6          ...                               1                       0   \n",
       "000c1a          ...                               0                       0   \n",
       "001c53          ...                               0                       1   \n",
       "001d44          ...                               0                       0   \n",
       "002b2e          ...                               0                       1   \n",
       "\n",
       "         most_weekday_weekday_3  most_weekday_weekday_4  \\\n",
       "user_id                                                   \n",
       "0001c6                        0                       0   \n",
       "000c1a                        1                       0   \n",
       "001c53                        0                       0   \n",
       "001d44                        0                       0   \n",
       "002b2e                        0                       0   \n",
       "\n",
       "         most_weekday_weekday_5  most_weekday_weekday_6  \\\n",
       "user_id                                                   \n",
       "0001c6                        0                       0   \n",
       "000c1a                        0                       0   \n",
       "001c53                        0                       0   \n",
       "001d44                        0                       1   \n",
       "002b2e                        0                       0   \n",
       "\n",
       "         most_timeday_Afternoon  most_timeday_Evening  most_timeday_Morning  \\\n",
       "user_id                                                                       \n",
       "0001c6                        0                     1                     0   \n",
       "000c1a                        0                     0                     1   \n",
       "001c53                        0                     0                     1   \n",
       "001d44                        0                     0                     1   \n",
       "002b2e                        0                     1                     0   \n",
       "\n",
       "         most_timeday_Night  \n",
       "user_id                      \n",
       "0001c6                    0  \n",
       "000c1a                    0  \n",
       "001c53                    0  \n",
       "001d44                    0  \n",
       "002b2e                    0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure we have the right input database\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.44833333e-01,   3.18047633e+02,   1.98035000e+00,\n",
       "         1.00590667e+01,   0.00000000e+00,   4.79261667e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure we have the right output\n",
    "target[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='define_baseline'></a>\n",
    "## Define a Baseline\n",
    "\n",
    "As mentionned before we should have a baseline to compare the performance of our models with. Here as we are forecasting a quantitative variable, a simple model is for example the one that predicts a constant value like the mean or the median we can observe on our past data. \n",
    "\n",
    "Note as well that by default `scikit` _maximises_ metrics. Error metrics have been implemented as a negative number within the scoring function even if that is different to the usual. We therefore negate the baseline numbers to make them comparable and look for those models that maximise this number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a baseline to compare our results to (mean and median minutes watched and 0)\n",
    "mean=np.mean(target)\n",
    "median=np.median(target)\n",
    "\n",
    "mean_forecast=[mean]*len(target)\n",
    "median_forecast=[median]*len(target)\n",
    "zero_forecast=[0]*len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 75.9168097123\n",
      "Median: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean: \"+str(mean))\n",
    "print(\"Median: \"+str(median))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median is null, meaning than more than half of our users don't consume content on iPlayer within the last two weeks. The constant model equal to 0 could thus be a good baseline to compare our results with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score if we forecast the mean: -115.319756974\n",
      "Score if we forecast the median: -75.9168097123\n",
      "Score if we forecast zero: -75.9168097123\n"
     ]
    }
   ],
   "source": [
    "# Compute the errors for these different baseline\n",
    "from sklearn import metrics\n",
    "print(\"Score if we forecast the mean:\",\n",
    "      -metrics.mean_absolute_error(target,mean_forecast))\n",
    "print(\"Score if we forecast the median:\",\n",
    "      -metrics.mean_absolute_error(target,median_forecast))\n",
    "print(\"Score if we forecast zero:\",\n",
    "      -metrics.mean_absolute_error(target,zero_forecast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try different kind of regressions. Note that these models are easy to interpret and we can __quantify the impact__ of our input variables on the target one here. \n",
    "\n",
    "<a id='linear_reg'></a>\n",
    "# Linear Regression\n",
    "\n",
    "The easiest way to relate our output variable to our input ones is to use a linear regression. In this modelling framework we explain the target by a __linear combinations__ of the inputs. For more details see: https://en.wikipedia.org/wiki/Linear_regression\n",
    "\n",
    "And for the `scikit learn` documentation: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's build a simple regression\n",
    "from sklearn import linear_model\n",
    "\n",
    "# We will use cross validation, so import helper functions for this\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "# Plots\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLABLABLA\n",
    "subset_features=list(features.columns)\n",
    "subset_features.remove('total_watched')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with this subset of input variables.\n",
    "\n",
    "<a id='model_training'></a>\n",
    "## Model Training\n",
    "\n",
    "With this kind of modelling there is no hyperparameter to tune. Indeed, the model only has to evaluate the contribution or _coefficient_ of each input variable in the linear combination.  \n",
    "\n",
    "The `cross_val_predicts` functions here returns, for each element in the input, the prediction that was obtained for that element when it was in the test set during the cross-validation process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We setup a simple linear regression, again using cross validation\n",
    "reg=linear_model.LinearRegression()\n",
    "\n",
    "predicted=cross_val_predict(reg, features[subset_features],target)\n",
    "scores=cross_val_score(reg, features[subset_features], target, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='out_sample_error'></a>\n",
    "## Out-of-Sample Error\n",
    "As for the classification part, we need to take the average of the different errors obtained during the cross-validation process to compute an out-of-sample error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: -58.2030737694\n"
     ]
    }
   ],
   "source": [
    "# Compute the mean error obtained in the CV\n",
    "print(\"Mean score:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__COMMENTS__ compare to baseline.\n",
    "\n",
    "We can also plot our predicted values against the output we actually observe. The more the dots are close to the first bisector, the better are our forecasts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/z/NkI6jCp3K9wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a127570f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's compare graphically the predicted and actual values\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(target, predicted)\n",
    "ax.plot([target.min(), target.max()], [target.min(), target.max()], 'k--', lw=1)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__COMMENTS__\n",
    "\n",
    "<a id='in_sample_error'></a>\n",
    "## In-Sample Error and Estimated Coefficients\n",
    "Let's now train on our entire dataset and have a look at the estimated coefficients to get the patterns the model detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's train on all data \n",
    "lin_reg=linear_model.LinearRegression()\n",
    "mod1=lin_reg.fit(features[subset_features],target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-56.684464113536954"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In-sample error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "-metrics.mean_absolute_error(target,mod1.predict(features[subset_features]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remind that it is usual to have a smaller in-sample error as the output data we are comparing our forecasts with has been used to train the model.\n",
    "\n",
    "For the estimated coefficients we should have a look at the __p-values__ - statistic values that indicate whether our estimated coefficient is significantly different from zero. __MORE DETAILS__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.849595</td>\n",
       "      <td>most_weekday_weekday_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.835055</td>\n",
       "      <td>most_genre_Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.115684</td>\n",
       "      <td>most_genre_Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.144480</td>\n",
       "      <td>average_completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.279421</td>\n",
       "      <td>most_genre_Entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   coefficient                   feature\n",
       "0     6.849595    most_weekday_weekday_2\n",
       "1     5.835055          most_genre_Drama\n",
       "2     5.115684          most_genre_Sport\n",
       "3     4.144480        average_completion\n",
       "4     2.279421  most_genre_Entertainment"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a look at the estimated coefficients\n",
    "coef1=pd.DataFrame(\n",
    "    {'feature': list(features[subset_features].columns),\n",
    "     'coefficient': list(mod1.coef_)\n",
    "    })\n",
    "coef1.sort_values(by='coefficient', ascending=False).reset_index(drop=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-6.847484</td>\n",
       "      <td>most_timeday_Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-7.636982</td>\n",
       "      <td>most_weekday_weekday_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-9.135321</td>\n",
       "      <td>most_timeday_Evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-9.727312</td>\n",
       "      <td>most_weekday_weekday_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-19.409614</td>\n",
       "      <td>most_genre_Children's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    coefficient                 feature\n",
       "30    -6.847484      most_timeday_Night\n",
       "31    -7.636982  most_weekday_weekday_1\n",
       "32    -9.135321    most_timeday_Evening\n",
       "33    -9.727312  most_weekday_weekday_0\n",
       "34   -19.409614   most_genre_Children's"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef1.sort_values(by='coefficient', ascending=False).reset_index(drop=True).tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__COMMENTS__\n",
    "\n",
    "<a id='ridge_reg'></a>\n",
    "# Ridge Regression\n",
    "\n",
    "__DETAILS __\n",
    "\n",
    "`scikit documentation`: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
    "\n",
    "<a id='model_training2'></a>\n",
    "## Model Training and Hyperparameters Tuning\n",
    "\n",
    "We need to tune the penalty parameter _alpha_. Let's have the same approach than for the classification part and do a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the model and develop a simple grid search against some key parameters\n",
    "param_alpha=[0.001,0.01,0.1,1.0,10,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's keep track of our best parameters\n",
    "best_score=-200\n",
    "best_param=0\n",
    "\n",
    "# we will setup a manual grid search, but you can also use the gridsearchCV capability in sklearn\n",
    "for i in param_alpha:\n",
    "    reg_r = linear_model.Ridge(alpha = i)\n",
    "    scores=cross_val_score(reg_r,\n",
    "                           features,\n",
    "                           target,\n",
    "                           scoring='neg_mean_absolute_error')\n",
    "    if np.mean(scores)>best_score:\n",
    "        best_score=np.mean(scores)\n",
    "        best_param=i\n",
    "\n",
    "# print the overall best results\n",
    "print('Best Settings: alpha:',best_param)\n",
    "print('Score:', best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__COMMENTS__\n",
    "\n",
    "<a id='best_ridge_reg'></a>\n",
    "## Best Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's keep our best model (hyperparameters tuned)\n",
    "ridge=linear_model.Ridge(alpha = best_param)\n",
    "mod2=ridge.fit(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-sample error\n",
    "-metrics.mean_absolute_error(target,mod2.predict(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare graphically the predicted and actual values\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(target, mod2.predict(features))\n",
    "ax.plot([target.min(), target.max()], [target.min(), target.max()], 'k--', lw=1)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__COMMENTS__\n",
    "\n",
    "<a id='lasso_reg'></a>\n",
    "# Lasso Regression\n",
    "\n",
    "__DETAILS __\n",
    "\n",
    "`scikit documentation`: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
    "\n",
    "<a id='model_training3'></a>\n",
    "## Model Training and Hyperparameters Tuning\n",
    "\n",
    "Again we need to tune the penalty parameter _alpha_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the model and develop a simple grid search against some key parameters\n",
    "param_alpha=[0.001,0.01,0.1,1.0,10,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's keep track of our best parameters\n",
    "best_score=-200\n",
    "best_param=0\n",
    "\n",
    "# we will setup a manual grid search, but you can also use the gridsearchCV capability in sklearn\n",
    "for i in param_alpha:\n",
    "    reg_r = linear_model.LassoLars(alpha = i)\n",
    "    scores=cross_val_score(reg_r,\n",
    "                           features,\n",
    "                           target,\n",
    "                           scoring='neg_mean_absolute_error')\n",
    "    if np.mean(scores)>best_score:\n",
    "        best_score=np.mean(scores)\n",
    "        best_param=i\n",
    "\n",
    "# print the overall best results\n",
    "print('Best Settings: alpha:',best_param)\n",
    "print('Score:', best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__COMMENTS__\n",
    "\n",
    "<a id='best_lasso_reg'></a>\n",
    "## Best Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's keep our best model (hyperparameters tuned)\n",
    "lasso=linear_model.LassoLars(alpha = best_param)\n",
    "mod3=lasso.fit(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-sample error\n",
    "-metrics.mean_absolute_error(target,mod3.predict(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare graphically the predicted and actual values\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(target, mod3.predict(features))\n",
    "ax.plot([target.min(), target.max()], [target.min(), target.max()], 'k--', lw=1)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__COMMENTS__\n",
    "\n",
    "<a id='combine'></a>\n",
    "# Combine the Regression and Classification Models\n",
    "and generate an overall score \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
